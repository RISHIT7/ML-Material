{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative loop of machine learning development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Choose the architecture (model, data, etc.)\n",
    "2) Train model\n",
    "3) Diagnostics\n",
    "4) Step 1!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accoding to Andrew the best way of looking at performance is bias and Variance and the second best is the following error analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually looking at what training examples were miss calssified and then doing the needed changes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Data/Creating Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's tempting to get more data of everything but that is not feaasible.\n",
    "\n",
    "So it is better to gather data related to the features wich are getting most mis-classified."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond just getting more training sets, we can use something called __Data Augmentation__ <br>\n",
    "\n",
    "__For example:__ <br>\n",
    "1) Let's say we are trying to classify the number of letter of the alphabet and A is getting the most mis-classified, then we may produce more A's by changing the contrast of the image, or rotating the image, or rescaling the image, or may even take the mirror image. Basically do any distortions of the letter A\n",
    "2) for Speech data, we can add different types of noises, like car noise or crowd noise, to create more data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can do __Data Synthesis__\n",
    "\n",
    "__For Example:__\n",
    "1) We can create the datas, as done for phot OCR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning: using data from different task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we wanted to make a handwritten digit classifier, but we did not have many images, then we can train the neural network on first data of let's say 1,000 outputs which may range from humans to cats dogs etc. and then make a copy of that neural network and change only the output layer and trin it on the digits data that we have"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have two options:\n",
    "1) Only train __output layers__ and hold the other parameters fixed\n",
    "2) __train all the parameters__\n",
    "\n",
    "Now, if you have a very small training set, then 1 works better, and if you have a large learning set then 2 works better"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is known as supervised pretraining and then finetuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hence the steps are:\n",
    "1) Download a nneural network parameters pretrained on a large dataset with same input type as you application.\n",
    "\n",
    "2) Further train the network on your own data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewed Datasets\n",
    "Datasets where the output is has far from equal frequency"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take an example of a rare disease, let's say it's a disease that noyl affects 0.5% of all people, then if our model has accuracy of 1% is not very good, because even print(\"y=0\") will have greater accuracy...\n",
    "\n",
    "So to comment on accuracy we make a precision matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision/Recall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{bmatrix} \\text{matrix} & 1 & 0 \\\\ 1 & \\text{true positive} & \\text{false positive} \\\\ 0 & \\text{false negative} & \\text{true negative}\\end{bmatrix}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Precision:=__ $\\frac{\\text{True positives}}{\\text{True pos} + \\text{False pos}}$ <br>\n",
    "of all the patients which were predicted positive how many were actually positive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Recall:=__ $\\frac{\\text{True positives}}{\\text{True pos} + \\text{False neg}}$ <br>\n",
    "of all the patients that actually have the rare diseaase, what fraction did we correctly detect as having it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trade of between precision and recall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can raise the threshold of the machine that will increase the precision but lower recall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or can decrease the threshold to increase the recall but at the same time lower precision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes by plotting Recall vs Precision we can can find what value of threshold to choose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score\n",
    "Is sometimes used to calculate the value of threshold from combining precision and recall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$F_1 \\text{score} = \\frac{1}{\\frac{1}{2}(\\frac{1}{P} + \\frac{1}{R})}$$\n",
    "\n",
    "aka the harmonic mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED FUNCTION: select_threshold\n",
    "\n",
    "def select_threshold(y_val, p_val): \n",
    "    \"\"\"\n",
    "    Finds the best threshold to use for selecting outliers \n",
    "    based on the results from a validation set (p_val) \n",
    "    and the ground truth (y_val)\n",
    "    \n",
    "    Args:\n",
    "        y_val (ndarray): Ground truth on validation set\n",
    "        p_val (ndarray): Results on validation set\n",
    "        \n",
    "    Returns:\n",
    "        epsilon (float): Threshold chosen \n",
    "        F1 (float):      F1 score by choosing epsilon as threshold\n",
    "    \"\"\" \n",
    "\n",
    "    best_epsilon = 0\n",
    "    best_F1 = 0\n",
    "    F1 = 0\n",
    "    \n",
    "    step_size = (max(p_val) - min(p_val)) / 1000\n",
    "    \n",
    "    for epsilon in np.arange(min(p_val), max(p_val), step_size):\n",
    "    \n",
    "        ### START CODE HERE ### \n",
    "        predictions = (p_val < epsilon)\n",
    "        \n",
    "        tp = np.sum((predictions == True) & (y_val == 1))\n",
    "        fn = np.sum((predictions == False) & (y_val == 1))\n",
    "        fp = np.sum((predictions == True) & (y_val == 0))\n",
    "        \n",
    "        prec = tp/(tp+fp)\n",
    "        rec = tp/(tp+fn)\n",
    "        \n",
    "        F1 = 2*(prec*rec)/(prec+rec)\n",
    "        \n",
    "        ### END CODE HERE ### \n",
    "        \n",
    "        if F1 > best_F1:\n",
    "            best_F1 = F1\n",
    "            best_epsilon = epsilon\n",
    "        \n",
    "    return best_epsilon, best_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
