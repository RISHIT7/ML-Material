{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we form a cluster of points, and then through the centroid, we calculate the probabililty of this function being okay, the farther the point the lower probability it has of being a normal input, and higher probability of it being an anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian/Normal/Bell_shape Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Formula is:\n",
    "$$p(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{\\frac{-(x-\\mu)^2}{2\\sigma^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum likelihood for $\\mu$, $\\sigma$\n",
    "$$\\mu = \\frac{1}{m}\\sum_{i=1}^{m}x^{(i)}$$\n",
    "$$\\sigma^2 = \\frac{1}{m}\\sum_{i=1}^{m}(x^{(i)}-\\mu)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incase of multiple features\n",
    "$$p(\\vec{x}) = p(x_1;\\mu_1,\\sigma_1^2)*p(x_2;\\mu_2,\\sigma_2^2)*...*p(x_n;\\mu_n,\\sigma_n^2)$$\n",
    "Or,\n",
    "$$p(\\vec{x})=\\prod_{j=1}^{n}p(x_i;\\mu_i, \\sigma_j^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The importance of real-number evalutaion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When developing a learning algorithm, making decision is much easier if we have a way of evaluating our learning algorithm.\n",
    "\n",
    "Assume we have some labeled data, of anomalous(1) and non-anomalous(0) examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm works better if we create a x_cv and include some anomalour data into the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For example:__ <br>\n",
    "To tune the parameter $\\epsilon$ <br>\n",
    "\n",
    "Training set: 6000 good engines <br>\n",
    "CV: 2000 good engines and 10 anomalous <bR>\n",
    "Test: 2000 good engines and 10 anomalous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm evaluation\n",
    "Fit model on training set <br>\n",
    "On a cross validation/test example, predict the value <br>\n",
    "And use the skewed data sets diagnostics, that is the F1 score for the classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly detection vs Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anomaly Detection\n",
    "1) Very small positive examples and large number of negative examples (0-20)\n",
    "2) Many different \"types\" of anomalie. Hard for any algorithm to learn from positive examples what the anoalies look like; future anomalies may look nothing like any of the anomalous examplews we've seen so far\n",
    "\n",
    "#### Supervised Learning\n",
    "1) Large number of positive and negative examples\n",
    "2) Enough positive examples for algorithm to get a sense of what positive examples likely to be similar to ones in training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing what features to choose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very important to choose the right features in anomaly detection even more regourously than in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the features that you give it are gaussian, if not, then change it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using ply.hist() plot the data, and if the feature is gaussian, then use it <br>\n",
    "If not maybe take the log of that feature, and that may make it more gaussian, try using __log(x+c)__ or some __fractional power of x__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis for anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want p(x) to be large for normal and p(x) to be ver small to anomalous examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these cases, if we can look at the error, in case, let's say an anomaly is detected with a high p(x) value, that is, very close to a normal feature, If we can investigate and find another feature, that helps  use distingiush the two, maybe asking self \"What made me think it was an anomaly\" will help creating a better algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_gaussian(X): \n",
    "    \"\"\"\n",
    "    Calculates mean and variance of all features \n",
    "    in the dataset\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray): (m, n) Data matrix\n",
    "    \n",
    "    Returns:\n",
    "        mu (ndarray): (n,) Mean of all features\n",
    "        var (ndarray): (n,) Variance of all features\n",
    "    \"\"\"\n",
    "\n",
    "    m, n = X.shape\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    mu = np.zeros(n)\n",
    "    var = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        mu[i] = np.mean(X[:,i])\n",
    "        var[i] = np.var(X[:,i])\n",
    "    ### END CODE HERE ### \n",
    "        \n",
    "    return mu, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 4.]), array([2.66666667, 2.66666667]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_gaussian(np.array([[1, 2], [3, 4], [5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED FUNCTION: select_threshold\n",
    "\n",
    "def select_threshold(y_val, p_val): \n",
    "    \"\"\"\n",
    "    Finds the best threshold to use for selecting outliers \n",
    "    based on the results from a validation set (p_val) \n",
    "    and the ground truth (y_val)\n",
    "    \n",
    "    Args:\n",
    "        y_val (ndarray): Ground truth on validation set\n",
    "        p_val (ndarray): Results on validation set\n",
    "        \n",
    "    Returns:\n",
    "        epsilon (float): Threshold chosen \n",
    "        F1 (float):      F1 score by choosing epsilon as threshold\n",
    "    \"\"\" \n",
    "\n",
    "    best_epsilon = 0\n",
    "    best_F1 = 0\n",
    "    F1 = 0\n",
    "    \n",
    "    step_size = (max(p_val) - min(p_val)) / 1000\n",
    "    \n",
    "    for epsilon in np.arange(min(p_val), max(p_val), step_size):\n",
    "    \n",
    "        ### START CODE HERE ### \n",
    "\n",
    "        ### END CODE HERE ### \n",
    "        \n",
    "        if F1 > best_F1:\n",
    "            best_F1 = F1\n",
    "            best_epsilon = epsilon\n",
    "        \n",
    "    return best_epsilon, best_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val = [0.4, 0.3, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED FUNCTION: select_threshold\n",
    "\n",
    "def select_threshold(y_val, p_val): \n",
    "    \"\"\"\n",
    "    Finds the best threshold to use for selecting outliers \n",
    "    based on the results from a validation set (p_val) \n",
    "    and the ground truth (y_val)\n",
    "    \n",
    "    Args:\n",
    "        y_val (ndarray): Ground truth on validation set\n",
    "        p_val (ndarray): Results on validation set\n",
    "        \n",
    "    Returns:\n",
    "        epsilon (float): Threshold chosen \n",
    "        F1 (float):      F1 score by choosing epsilon as threshold\n",
    "    \"\"\" \n",
    "\n",
    "    best_epsilon = 0\n",
    "    best_F1 = 0\n",
    "    F1 = 0\n",
    "    \n",
    "    step_size = (max(p_val) - min(p_val)) / 1000\n",
    "    \n",
    "    for epsilon in np.arange(min(p_val), max(p_val), step_size):\n",
    "    \n",
    "        ### START CODE HERE ### \n",
    "        predictions = (p_val < epsilon)\n",
    "        \n",
    "        tp = np.sum((predictions == True) & (y_val == 1))\n",
    "        fn = np.sum((predictions == False) & (y_val == 1))\n",
    "        fp = np.sum((predictions == True) & (y_val == 0))\n",
    "        \n",
    "        prec = tp/(tp+fp)\n",
    "        rec = tp/(tp+fn)\n",
    "        \n",
    "        F1 = 2*(prec*rec)/(prec+rec)\n",
    "        \n",
    "        ### END CODE HERE ### \n",
    "        \n",
    "        if F1 > best_F1:\n",
    "            best_F1 = F1\n",
    "            best_epsilon = epsilon\n",
    "        \n",
    "    return best_epsilon, best_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
