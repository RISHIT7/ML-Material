{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n","\n","# # Load the model and tokenizer from the saved directory\n","# # model_dir = \"/kaggle/working/my_model\"\n","# model_dir = \"microsoft/Phi-3-mini-4k-instruct\"\n","# model = AutoModelForCausalLM.from_pretrained(model_dir)\n","# tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","\n","# # Save the model and tokenizer to the local filesystem\n","# model.save_pretrained(\"/kaggle/working/my_model\")\n","# tokenizer.save_pretrained(\"/kaggle/working/my_model\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the model and tokenizer from the saved directory\n","model_dir = \"/kaggle/working/my_model\"\n","model = AutoModelForCausalLM.from_pretrained(model_dir)\n","tokenizer = AutoTokenizer.from_pretrained(model_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a text generation pipeline\n","text_generator = pipeline(\n","    task=\"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    device=0,  # Use GPU if available\n","    framework=\"pt\",  # PyTorch framework\n","    temperature=0.5,\n","    do_sample=True,\n","    max_length=500  # Adjusted from max_new_tokens to max_length\n",")\n","\n","# Example usage\n","prompt = \"What happend, Once upon a time?\"\n","generated_text = text_generator(prompt)\n","print(generated_text)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_huggingface import HuggingFacePipeline\n","hf = HuggingFacePipeline(pipeline = text_generator)\n","hf.invoke(\"Hello!\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain.prompts import PromptTemplate\n","\n","def generate_restaurant_name_and_items(cuisine):\n","    # Chain 1: Restaurant Name\n","    prompt_template_name = PromptTemplate(\n","        input_variables = ['cuisine'],\n","        template = \"I want to open a new restaurant for {cuisine} cuisine. Can you suggest ONLY ONE name for my restaurant?, Give only name, nothing else!\"\n","    )\n","    \n","    name = hf.invoke(prompt_template_name.format(cuisine = cuisine))\n","#     chain = prompt_template_name | hf\n","#     name = chain.invoke()\n","    \n","    # Chain 2: Menu items\n","    prompt_template_name = PromptTemplate(\n","        input_variables= ['restaurant_name'],\n","        template = \"Suggest some menu items for {restaurant_name} No sentence, only name. Return it as a comma seperated string\"\n","    )\n","    \n","    menu_items = hf.invoke(prompt_template_name.format(restaurant_name = name))\n","#     chain = prompt_template_name | model\n","#     menu_items = chain.invoke({'restaurant_name': cuisine})\n","    \n","    return {\n","        'restaurant_name': name,\n","        'menu_items': menu_items\n","    }\n","\n","if __name__ == \"__main__\":\n","    print(generate_restaurant_name_and_items(\"Indian\")['restaurant_name'])\n","    print()\n","    print(generate_restaurant_name_and_items(\"Indian\")['menu_items'])"]}],"metadata":{"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}
